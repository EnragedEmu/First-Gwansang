{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeba_download_demo import Curdir_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_attr_celeba_filename = 'list_attr_celeba.txt'\n",
    "\n",
    "cl = Curdir_loader()\n",
    "df = cl.load_file_asDF(list_attr_celeba_filename).replace(to_replace=-1, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 202599\n",
    "train_size = 180000\n",
    "test_size = num_data - train_size - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lasso(nn.CrossEntropyLoss):\n",
    "\n",
    "            norm  = torch.FloatTensor([0])\n",
    "            for param in layers.parameters():\n",
    "                norm += torch.norm(param, p=1)\n",
    "            loss += lbd * norm.squeeze_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    accurate = 0\\n    for i in range(test_size):\\n        if torch.argmax(layers(X_test[i])) == torch.argmax(y_test[i]):\\n            accurate += 1\\n    print('Final test acc: ', accurate / test_size)\\n            \""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learn_and_eval(label):\n",
    "    X = df.drop(labels=0, axis=0).drop(['Name'], axis=1).drop([label], axis=1)\n",
    "    y = df[label]\n",
    "\n",
    "    X_train = X.iloc[:train_size]\n",
    "    y_train = y.iloc[:train_size]\n",
    "    X_test = X.iloc[train_size:]\n",
    "    y_test = y.iloc[train_size:]\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 2\n",
    "\n",
    "    X_train = torch.FloatTensor(X_train.values)\n",
    "    y_train = nn.functional.one_hot(torch.tensor(y_train.values), num_classes=2).type(torch.FloatTensor)\n",
    "    X_test = torch.FloatTensor(X_test.values)\n",
    "    y_test = nn.functional.one_hot(torch.tensor(y_test.values), num_classes=2).type(torch.FloatTensor)\n",
    "\n",
    "    layers = nn.Sequential(nn.Linear(input_size, 20), \n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(20, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, output_size))\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(layers.parameters())\n",
    "\n",
    "    epoch_num = 10\n",
    "    batch_iter = 100\n",
    "    batch_size = int(train_size / batch_iter)\n",
    "    X_train_batch = X_train.split(batch_size, dim=0)\n",
    "    y_train_batch = y_train.split(batch_size, dim=0)\n",
    "\n",
    "    true_positive, true_negative, false_positive, false_negative, true = 0, 0, 0, 0, 0\n",
    "    for i in range(test_size):\n",
    "        if torch.argmax(y_test[i]) == 0:\n",
    "            true += 1\n",
    "            if torch.argmax(layers(X_test[i])) == 0:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if torch.argmax(layers(X_test[i])) == 1:\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "    \n",
    "\n",
    "    print('Primary test acc: (True  positive: {:.4f}) | (True  negative: {:.4f})'.format(true_positive / test_size, true_negative / test_size))\n",
    "    print('                  (False negative: {:.4f}) | (False positive: {:.4f})'.format(false_negative / test_size, false_positive / test_size))\n",
    "\n",
    "    print()\n",
    "\n",
    "    lbd = 0.1\n",
    "    for epoch in range(epoch_num):\n",
    "        for i in range(batch_iter):\n",
    "            hypo = layers(X_train_batch[i])\n",
    "            loss = loss_fn(hypo, y_train_batch[i])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch: {:2d} | loss: {}'.format(epoch + 1, loss.item()))\n",
    "    \n",
    "    true_positive, true_negative, false_positive, false_negative, true = 0, 0, 0, 0, 0\n",
    "    for i in range(test_size):\n",
    "        if torch.argmax(y_test[i]) == 0:\n",
    "            true += 1\n",
    "            if torch.argmax(layers(X_test[i])) == 0:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if torch.argmax(layers(X_test[i])) == 1:\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "    \n",
    "\n",
    "    print('\\nFinal test acc: (True  positive: {:.4f}) | (True  negative: {:.4f})'.format(true_positive / test_size, true_negative / test_size))\n",
    "    print('                (False negative: {:.4f}) | (False positive: {:.4f})'.format(false_negative / test_size, false_positive / test_size))\n",
    "\n",
    "'''\n",
    "    accurate = 0\n",
    "    for i in range(test_size):\n",
    "        if torch.argmax(layers(X_test[i])) == torch.argmax(y_test[i]):\n",
    "            accurate += 1\n",
    "    print('Final test acc: ', accurate / test_size)\n",
    "            '''\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test acc: (True  positive: 0.0000) | (True  negative: 0.3903)\n",
      "                  (False negative: 0.6097) | (False positive: 0.0000)\n",
      "\n",
      "Epoch:  1 | loss: 0.6916339993476868\n",
      "Epoch:  2 | loss: 0.6836643218994141\n",
      "Epoch:  3 | loss: 0.6841010451316833\n",
      "Epoch:  4 | loss: 0.7076199650764465\n",
      "Epoch:  5 | loss: 0.6865398287773132\n",
      "Epoch:  6 | loss: 0.6970726251602173\n",
      "Epoch:  7 | loss: 0.6956887245178223\n",
      "Epoch:  8 | loss: 0.6861046552658081\n",
      "Epoch:  9 | loss: 0.6964628100395203\n",
      "Epoch: 10 | loss: 0.6919003129005432\n",
      "\n",
      "Final test acc: (True  positive: 0.6030) | (True  negative: 0.0046)\n",
      "                (False negative: 0.0067) | (False positive: 0.3858)\n"
     ]
    }
   ],
   "source": [
    "learn_and_eval('Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary test acc: (True  positive: 0.0152) | (True  negative: 0.3911)\n",
      "                  (False negative: 0.5813) | (False positive: 0.0123)\n",
      "\n",
      "Epoch:  1 | loss: 1.1565254926681519\n",
      "Epoch:  2 | loss: 1.1570155620574951\n",
      "Epoch:  3 | loss: 1.2061915397644043\n",
      "Epoch:  4 | loss: 1.2011985778808594\n",
      "Epoch:  5 | loss: 1.1359009742736816\n",
      "Epoch:  6 | loss: 1.135117769241333\n",
      "Epoch:  7 | loss: 1.099778413772583\n",
      "Epoch:  8 | loss: 1.1018284559249878\n",
      "Epoch:  9 | loss: 1.1267027854919434\n",
      "Epoch: 10 | loss: 1.1535048484802246\n",
      "\n",
      "Final test acc: (True  positive: 0.5966) | (True  negative: 0.0000)\n",
      "                (False negative: 0.0000) | (False positive: 0.4034)\n"
     ]
    }
   ],
   "source": [
    "learn_and_eval('Heavy_Makeup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test acc: (True  positive: 0.2430) | (True  negative: 0.0000)\n",
      "                  (False negative: 0.0000) | (False positive: 0.7570)\n",
      "\n",
      "Epoch:  1 | loss: 0.6602745652198792\n",
      "Epoch:  2 | loss: 0.5876858830451965\n",
      "Epoch:  3 | loss: 0.5836073160171509\n",
      "Epoch:  4 | loss: 0.570396363735199\n",
      "Epoch:  5 | loss: 0.6058144569396973\n",
      "Epoch:  6 | loss: 0.5647022724151611\n",
      "Epoch:  7 | loss: 0.568134069442749\n",
      "Epoch:  8 | loss: 0.5794580578804016\n",
      "Epoch:  9 | loss: 0.5726785659790039\n",
      "Epoch: 10 | loss: 0.5667760968208313\n",
      "\n",
      "Final test acc: (True  positive: 0.0000) | (True  negative: 0.7570)\n",
      "                (False negative: 0.2430) | (False positive: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "learn_and_eval('Young')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test acc: (True  positive: 0.0000) | (True  negative: 0.0208)\n",
      "                  (False negative: 0.9792) | (False positive: 0.0000)\n",
      "\n",
      "Epoch:  1 | loss: 0.11429860442876816\n",
      "Epoch:  2 | loss: 0.269246369600296\n",
      "Epoch:  3 | loss: 0.1173100695014\n",
      "Epoch:  4 | loss: 0.10979069769382477\n",
      "Epoch:  5 | loss: 0.15397405624389648\n",
      "Epoch:  6 | loss: 0.14083194732666016\n",
      "Epoch:  7 | loss: 0.09608408808708191\n",
      "Epoch:  8 | loss: 0.11256446689367294\n",
      "Epoch:  9 | loss: 0.11404537409543991\n",
      "Epoch: 10 | loss: 0.09765629470348358\n",
      "\n",
      "Final test acc: (True  positive: 0.9792) | (True  negative: 0.0000)\n",
      "                (False negative: 0.0000) | (False positive: 0.0208)\n"
     ]
    }
   ],
   "source": [
    "learn_and_eval('Bald')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary test acc: (True  positive: 0.5056) | (True  negative: 0.0439)\n",
      "                  (False negative: 0.3923) | (False positive: 0.0582)\n",
      "\n",
      "Epoch:  1 | loss: 0.6394578814506531\n",
      "Epoch:  2 | loss: 0.4878097176551819\n",
      "Epoch:  3 | loss: 0.40749216079711914\n",
      "Epoch:  4 | loss: 0.4185389280319214\n",
      "Epoch:  5 | loss: 0.40696221590042114\n",
      "Epoch:  6 | loss: 0.39610716700553894\n",
      "Epoch:  7 | loss: 0.38670966029167175\n",
      "Epoch:  8 | loss: 0.3885786235332489\n",
      "Epoch:  9 | loss: 0.3973217308521271\n",
      "Epoch: 10 | loss: 0.40986335277557373\n",
      "\n",
      "Final test acc: (True  positive: 0.8979) | (True  negative: 0.0000)\n",
      "                (False negative: 0.0000) | (False positive: 0.1021)\n"
     ]
    }
   ],
   "source": [
    "learn_and_eval('5_o_Clock_Shadow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
